# Python RAG Service Configuration

# Flask Server
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_ENV=development

# FAISS Vector Store
FAISS_INDEX_PATH=./data/faiss_index
PDF_DIRECTORY=./data/pdfs

# Embeddings Model (HuggingFace)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# RAG Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RETRIEVAL=5

# Cloud LLM API Configuration
# Choose one: groq, together, fireworks, or openai
LLM_PROVIDER=groq

# API Keys (replace with your actual keys)
GROQ_API_KEY=your_groq_api_key_here
TOGETHER_API_KEY=your_together_api_key_here
FIREWORKS_API_KEY=your_fireworks_api_key_here

# Model Configuration
MODEL_NAME=llama3-8b-8192
MAX_TOKENS=1000
TEMPERATURE=0.3
